{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import copy\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif, VarianceThreshold"
      ],
      "metadata": {
        "id": "FJZ12Jnph8Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Mattliketocode/multiclass_mirna_model.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAUWitMdiBJi",
        "outputId": "30c733b7-d1c3-4f3e-f60e-ceea3bcd0980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multiclass_mirna_model'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 69 (delta 4), reused 0 (delta 0), pack-reused 51\u001b[K\n",
            "Unpacking objects: 100% (69/69), 64.95 MiB | 4.72 MiB/s, done.\n",
            "Updating files: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = tarfile.open('multiclass_mirna_model/breast.tar.gz')\n",
        "file.extractall('./breast')\n",
        "file.close()\n",
        "\n",
        "file = tarfile.open('multiclass_mirna_model/kidney.tar.gz')\n",
        "file.extractall('./kidney')\n",
        "file.close()\n",
        "\n",
        "file = tarfile.open('multiclass_mirna_model/corpus uteri.tar.gz')\n",
        "file.extractall('./corpus uteri')\n",
        "file.close()\n",
        "\n",
        "file = tarfile.open('multiclass_mirna_model/thyroid gland.tar.gz')\n",
        "file.extractall('./thyroid gland')\n",
        "file.close()\n",
        "\n",
        "file = tarfile.open('multiclass_mirna_model/bronchus and lung.tar.gz')\n",
        "file.extractall('./bronchus and lung')\n",
        "file.close()\n",
        "\n",
        "file = tarfile.open('multiclass_mirna_model/prostate gland.tar.gz')\n",
        "file.extractall('./prostate gland')\n",
        "file.close()\n",
        "\n",
        "file = tarfile.open('multiclass_mirna_model/brain.tar.gz')\n",
        "file.extractall('./brain')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "IJuaTmSgiG5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "3xMEtW2ZCCfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def clean_data(path, csv_path, n_of_samples, class_number):\n",
        "\n",
        "  manifest_path = path + '/MANIFEST.txt'\n",
        "  os.remove(manifest_path)\n",
        "\n",
        "  dir_list_0 = os.listdir(path)\n",
        "\n",
        "  for i in range(0, n_of_samples):\n",
        "    old_path = path + '/' + dir_list_0[i]\n",
        "    old_file = os.listdir(old_path)\n",
        "\n",
        "    for j in range(len(old_file)-1):\n",
        "      if old_file[j] == 'annotations.txt':\n",
        "        old_file.remove(old_file[j])\n",
        "\n",
        "    old_file_path = old_path + '/' + old_file[0]\n",
        "\n",
        "    shutil.move(old_file_path, path)\n",
        "    shutil.rmtree(old_path)\n",
        "\n",
        "  dir_list = os.listdir(path)\n",
        "\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  csv_path = 'multiclass_mirna_model' + '/' + csv_path\n",
        "  input_arr = np.loadtxt(csv_path, dtype='str', delimiter=',')\n",
        "  for i in range(0, n_of_samples):\n",
        "      for j in range(0, n_of_samples):\n",
        "\n",
        "          if input_arr[i][0] == dir_list[j]:\n",
        "              f_path = path + '/' + dir_list[j]\n",
        "              input_arr2 = np.genfromtxt(f_path, dtype='str', delimiter='\\t')\n",
        "              labels.append(input_arr[i][1])\n",
        "              data.append(input_arr2)\n",
        "\n",
        "  y_full = []\n",
        "  for x in range(len(labels)):\n",
        "      if labels[x] == \"Solid Tissue Normal\":\n",
        "          y_full.append(0)  ##0\n",
        "      else:\n",
        "          y_full.append(class_number)  ##1\n",
        "\n",
        "  x_full = []\n",
        "\n",
        "  data_copy = list(data)\n",
        "\n",
        "  miRNA_labels = []\n",
        "  flag = 0\n",
        "\n",
        "  for i in range(len(data_copy)):\n",
        "      data_copy[i] = list(data_copy[i])\n",
        "      data_copy[i].pop(0)\n",
        "      for j in range(len(data_copy[i])):\n",
        "          data_copy[i][j] = list(data_copy[i][j])\n",
        "          if flag == 0:\n",
        "            miRNA_labels.append(data_copy[i][j][0])\n",
        "          data_copy[i][j].pop(0)\n",
        "\n",
        "          data_copy[i][j][1] = float(data_copy[i][j][1])\n",
        "          data_copy[i][j].pop(0)\n",
        "          data_copy[i][j].pop(1)\n",
        "      flag = 1\n",
        "\n",
        "  for x in miRNA_labels:\n",
        "    x = str(x)\n",
        "\n",
        "  data_copy_2 = data_copy\n",
        "  for i in range(len(data_copy)):\n",
        "      data_copy_2[i] = np.resize(data_copy_2[i], 1881)\n",
        "\n",
        "  x_full = data_copy_2\n",
        "\n",
        "  return x_full, y_full, miRNA_labels"
      ],
      "metadata": {
        "id": "5pXaHcYZib1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./breast\"\n",
        "csv_path = \"breast.csv\"\n",
        "n_of_samples = 1207\n",
        "class_number = 1\n",
        "breast_x, breast_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "path = \"./kidney\"\n",
        "csv_path = \"kidney.csv\"\n",
        "n_of_samples = 616\n",
        "class_number = 2\n",
        "kidney_x, kidney_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "path = \"./corpus uteri\"\n",
        "csv_path = \"corpus uteri.csv\"\n",
        "n_of_samples = 568\n",
        "class_number = 3\n",
        "corpus_uteri_x, corpus_uteri_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "path = \"./thyroid gland\"\n",
        "csv_path = \"thyroid gland.csv\"\n",
        "n_of_samples = 573\n",
        "class_number = 4\n",
        "thyroid_gland_x, thyroid_gland_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "path = \"./bronchus and lung\"\n",
        "csv_path = \"bronchus and lung.csv\"\n",
        "n_of_samples = 567\n",
        "class_number = 5\n",
        "bronchus_and_lung_x, bronchus_and_lung_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "path = \"./prostate gland\"\n",
        "csv_path = \"prostate gland.csv\"\n",
        "n_of_samples = 551\n",
        "class_number = 6\n",
        "prostate_gland_x, prostate_gland_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "path = \"./brain\"\n",
        "csv_path = \"brain.csv\"\n",
        "n_of_samples = 530\n",
        "class_number = 7\n",
        "brain_x, brain_y, labels = clean_data(path, csv_path, n_of_samples, class_number)\n",
        "\n",
        "data_x = copy.deepcopy(breast_x + kidney_x + corpus_uteri_x + thyroid_gland_x + bronchus_and_lung_x + prostate_gland_x + brain_x)\n",
        "data_y = copy.deepcopy(breast_y + kidney_y + corpus_uteri_y + thyroid_gland_y + bronchus_and_lung_y + prostate_gland_y + brain_y)"
      ],
      "metadata": {
        "id": "YJCxd9FHihtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "qLUJPiWVCKr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def myTransform(x):\n",
        "  return np.log2(x+1)"
      ],
      "metadata": {
        "id": "82jboBnpkZt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(x, labels):\n",
        "  x_df = pd.DataFrame(data=x, columns=labels)\n",
        "  x_df = x_df.applymap(myTransform)\n",
        "\n",
        "  mapper = DataFrameMapper([(x_df.columns, StandardScaler())])\n",
        "  scaled_features = mapper.fit_transform(x_df.copy(), 1881)\n",
        "  scaled_features_df = pd.DataFrame(scaled_features, index=x_df.index, columns=x_df.columns)\n",
        "\n",
        "  return scaled_features_df"
      ],
      "metadata": {
        "id": "905Wn_Q4kGLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_standardize(x):\n",
        "  input_array = x\n",
        "  for i in range(len(input_array)):\n",
        "    for j in range(len(input_array[i])):\n",
        "      input_array[i][j] = math.log2(input_array[i][j] + 1)\n",
        "\n",
        "  return input_array"
      ],
      "metadata": {
        "id": "LattasO5kbZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extraction_x = standardize(copy.deepcopy(data_x), labels)\n",
        "feature_extraction_y = copy.deepcopy(data_y)\n",
        "\n",
        "x = log_standardize(copy.deepcopy(data_x))\n",
        "y = copy.deepcopy(data_y)"
      ],
      "metadata": {
        "id": "8HoG13fNkd1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top 20 Feature Selection"
      ],
      "metadata": {
        "id": "7tvzGuC0CGQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(x_df, y, number_of_features):\n",
        "\n",
        "  #remove zeros accross all samples\n",
        "  selector_1 = VarianceThreshold()\n",
        "  selector_1.fit_transform(x_df)\n",
        "  x = x_df.columns[selector_1.get_support()]\n",
        "\n",
        "  x_df = selector_1.fit_transform(x_df)\n",
        "  x_df = pd.DataFrame(data=x_df, columns=x)\n",
        "\n",
        "  selector = SelectKBest(mutual_info_classif, k=number_of_features)\n",
        "  selector.fit_transform(x_df, y)\n",
        "  top_features = x_df.columns[selector.get_support()]\n",
        "\n",
        "  x = PrettyTable()\n",
        "  x.add_column('Feature', top_features)\n",
        "  #print(x)\n",
        "  return top_features"
      ],
      "metadata": {
        "id": "VJ9bt3dikQ2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = extract_features(feature_extraction_x, feature_extraction_y, 20)"
      ],
      "metadata": {
        "id": "6f5q7vjAlrgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "id": "hhonB9xll3pV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aff9087-8669-4fb8-fb0c-e7bfd5b74742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['hsa-mir-10a', 'hsa-mir-10b', 'hsa-mir-135a-1', 'hsa-mir-135a-2',\n",
            "       'hsa-mir-135b', 'hsa-mir-141', 'hsa-mir-181a-2', 'hsa-mir-196a-1',\n",
            "       'hsa-mir-196a-2', 'hsa-mir-196b', 'hsa-mir-199b', 'hsa-mir-200a',\n",
            "       'hsa-mir-200b', 'hsa-mir-200c', 'hsa-mir-205', 'hsa-mir-375',\n",
            "       'hsa-mir-429', 'hsa-mir-9-1', 'hsa-mir-9-2', 'hsa-mir-9-3'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Models"
      ],
      "metadata": {
        "id": "tsQZzR41CTtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=200)\n",
        "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
        "                                ['classifier', clf]])\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "accuracy = cross_val_score(pipeline, x, y, cv = cv)\n",
        "precision = cross_val_score(pipeline, x, y, cv = cv, scoring='precision_macro')\n",
        "recall = cross_val_score(pipeline, x, y, cv = cv, scoring='recall_macro')"
      ],
      "metadata": {
        "id": "Bk2VFPvEmRv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(accuracy))"
      ],
      "metadata": {
        "id": "2T0VW_Udnnhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a145378-d7fe-4915-e3ac-ed68b13a9025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9817890825681606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(precision))"
      ],
      "metadata": {
        "id": "MYIhf9XGnqJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0233f2-ce08-4f29-a046-9973953c3bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9814810364241172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(recall))"
      ],
      "metadata": {
        "id": "2MhVy237nrnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e192385e-ad01-4f4d-bf87-95b3357fc629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9792658812886503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel=\"linear\")\n",
        "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
        "                                ['classifier', clf]])\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "accuracy = cross_val_score(pipeline, x, y, cv = cv)\n",
        "precision = cross_val_score(pipeline, x, y, cv = cv, scoring='precision_macro')\n",
        "recall = cross_val_score(pipeline, x, y, cv = cv, scoring='recall_macro')"
      ],
      "metadata": {
        "id": "LDVuuXiJotI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(accuracy))"
      ],
      "metadata": {
        "id": "TsYbqONzo48Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708df0aa-be78-4fd1-9a82-c4886b7c4f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9820036521481634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(precision))"
      ],
      "metadata": {
        "id": "osrQQ0lmo6WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a1ad5e-abd7-4328-978c-f4739abb900d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.978631832393232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(recall))"
      ],
      "metadata": {
        "id": "C9MPU-bZo8Rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e3b8d4-2d73-4689-85a5-40ae89844e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9806587575887147\n"
          ]
        }
      ]
    }
  ]
}